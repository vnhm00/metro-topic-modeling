{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Topic Modeling with Gensim\n",
    "Update: 12.04.2021<br>\n",
    "Mai Vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "#Libraries for lemmatization\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Lirary to check the language in text\n",
    "from langdetect import detect\n",
    "\n",
    "#Libraries for topic modeling\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pprint\n",
    "from gensim import models\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before deleting non-English abstracts:  11528\n",
      "Number of rows after:  11506\n"
     ]
    }
   ],
   "source": [
    "eng_data = pd.read_csv('eng_theseus_abstract.csv')\n",
    "print('Number of rows before deleting non-English abstracts: ', len(eng_data))\n",
    "\n",
    "#Data was extracted from the raw data with conditions such as 'language' = 'en'.\n",
    "#But still there are Finnish, Swedish, even Chinese abstracts in the dataset.\n",
    "#Here, those are deleted using langdetect library\n",
    "eng_data = eng_data[eng_data['abstract_en'].map(detect) == 'en']\n",
    "print('Number of rows after: ', len(eng_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create eng_stopwords set and lemmatizer from NLTK library\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "eng_stopwords.update('also', 'used')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Tokenization and delete punctuation, number, and stopwords\n",
    "abstracts = [[lemmatizer.lemmatize(word) for word in nltk.word_tokenize(abstract.lower())\n",
    "                                     if word.isalpha() and word not in eng_stopwords]\n",
    "              for abstract in eng_data['abstract_en']]\n",
    "\n",
    "#Some words appear very few times. If we count all words, there will be 32k unique tokens.\n",
    "#Here, we delete words that appear less than 3 times. Thus, unique tokens are nearly 16k.\n",
    "count = defaultdict(int) #Count word frequencies\n",
    "for abstract in abstracts:\n",
    "    for token in abstract:\n",
    "        count[token] += 1\n",
    "processed_abstracts = [[token for token in abstract if count[token] > 2] for abstract in abstracts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Converting corpus into list of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(15746 unique tokens: ['aaltonen', 'activity', 'actual', 'aim', 'also']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(processed_abstracts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19, 2),\n",
      " (24, 1),\n",
      " (40, 1),\n",
      " (45, 1),\n",
      " (60, 2),\n",
      " (65, 1),\n",
      " (73, 1),\n",
      " (149, 1),\n",
      " (155, 3),\n",
      " (167, 2),\n",
      " (224, 1),\n",
      " (228, 1),\n",
      " (252, 1),\n",
      " (299, 2),\n",
      " (301, 1),\n",
      " (316, 1),\n",
      " (342, 2),\n",
      " (346, 1),\n",
      " (467, 1),\n",
      " (471, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Create the bag of words for all documents\n",
    "bow_corpus = [dictionary.doc2bow(abstract) for abstract in processed_abstracts]\n",
    "\n",
    "#Print first 20 words in a random abstract\n",
    "pprint.pprint(bow_corpus[random.randint(0, 1000)][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LDA Model with 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_model = LdaModel(bow_corpus, num_topics = 10, id2word = dictionary, passes = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"study\" + 0.011*\"research\" + 0.010*\"country\" + 0.008*\"risk\" + 0.007*\"financial\" + 0.007*\"data\" + 0.006*\"economic\" + 0.006*\"impact\" + 0.006*\"economy\" + 0.005*\"also\"'),\n",
       " (1,\n",
       "  '0.020*\"research\" + 0.017*\"tourism\" + 0.012*\"survey\" + 0.010*\"consumer\" + 0.010*\"thesis\" + 0.010*\"study\" + 0.010*\"result\" + 0.009*\"hotel\" + 0.008*\"questionnaire\" + 0.007*\"restaurant\"'),\n",
       " (2,\n",
       "  '0.021*\"company\" + 0.021*\"process\" + 0.020*\"management\" + 0.017*\"study\" + 0.014*\"research\" + 0.014*\"case\" + 0.013*\"thesis\" + 0.012*\"project\" + 0.010*\"employee\" + 0.009*\"organization\"'),\n",
       " (3,\n",
       "  '0.027*\"health\" + 0.024*\"care\" + 0.020*\"study\" + 0.015*\"patient\" + 0.015*\"nurse\" + 0.010*\"research\" + 0.010*\"nursing\" + 0.009*\"review\" + 0.009*\"literature\" + 0.009*\"used\"'),\n",
       " (4,\n",
       "  '0.019*\"student\" + 0.012*\"study\" + 0.010*\"thesis\" + 0.009*\"university\" + 0.009*\"work\" + 0.009*\"education\" + 0.008*\"research\" + 0.008*\"finland\" + 0.007*\"also\" + 0.007*\"group\"'),\n",
       " (5,\n",
       "  '0.019*\"energy\" + 0.011*\"waste\" + 0.010*\"thesis\" + 0.010*\"water\" + 0.008*\"building\" + 0.008*\"material\" + 0.008*\"environmental\" + 0.007*\"construction\" + 0.007*\"production\" + 0.007*\"cost\"'),\n",
       " (6,\n",
       "  '0.033*\"company\" + 0.030*\"customer\" + 0.030*\"business\" + 0.026*\"service\" + 0.023*\"market\" + 0.018*\"research\" + 0.017*\"thesis\" + 0.012*\"product\" + 0.010*\"study\" + 0.010*\"case\"'),\n",
       " (7,\n",
       "  '0.019*\"system\" + 0.015*\"thesis\" + 0.012*\"test\" + 0.011*\"design\" + 0.011*\"software\" + 0.010*\"used\" + 0.010*\"data\" + 0.010*\"result\" + 0.009*\"project\" + 0.008*\"testing\"'),\n",
       " (8,\n",
       "  '0.024*\"application\" + 0.017*\"user\" + 0.016*\"thesis\" + 0.014*\"project\" + 0.012*\"development\" + 0.011*\"system\" + 0.011*\"mobile\" + 0.011*\"technology\" + 0.011*\"design\" + 0.010*\"game\"'),\n",
       " (9,\n",
       "  '0.042*\"marketing\" + 0.021*\"thesis\" + 0.019*\"medium\" + 0.018*\"social\" + 0.016*\"research\" + 0.015*\"brand\" + 0.014*\"company\" + 0.011*\"event\" + 0.010*\"study\" + 0.009*\"strategy\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some topics are quite well-defined, such as topic 1 (Tourism), topic 3 (Healthcare), topic 8 (Information Technology), topic 9 (Marketing), \n",
    "- Some topics, such as 0, 2, and 4, are not so clear.\n",
    "- Some meaningless keywords appear, such as \"thesis\", \"used\", \"also\", \"part\", \"work\". Might need to delete in the preprocessing stage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
